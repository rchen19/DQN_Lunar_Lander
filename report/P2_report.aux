\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{MnihPlayingAtariDeep2013,RoderickImplementingDeepQNetwork2017}
\citation{MnihPlayingAtariDeep2013,RoderickImplementingDeepQNetwork2017}
\@writefile{toc}{\contentsline {section}{\numberline {1}Game: LunarLander-v2}{1}{section.1}}
\newlabel{game}{{1}{1}{Game: LunarLander-v2}{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An illustration of the LunarLander-v2 environment from \burl  {https://gym.openai.com/envs/LunarLander-v2/}.\relax }}{1}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:lunarlander}{{1}{1}{An illustration of the LunarLander-v2 environment from \burl {https://gym.openai.com/envs/LunarLander-v2/}.\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Experiments and Results}{1}{section.2}}
\newlabel{experiments}{{2}{1}{Experiments and Results}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Experiment 1}{2}{subsection.2.1}}
\newlabel{experiment1}{{2.1}{2}{Experiment 1}{subsection.2.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces DQN with fixed Q-targets and experience replay\relax }}{2}{algorithm.1}}
\newlabel{fig:train_param_0057}{{2a}{2}{\relax }{figure.caption.2}{}}
\newlabel{sub@fig:train_param_0057}{{a}{2}{\relax }{figure.caption.2}{}}
\newlabel{fig:test_param_0057}{{2b}{2}{\relax }{figure.caption.2}{}}
\newlabel{sub@fig:test_param_0057}{{b}{2}{\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces DQN with fixed Q-targets (updating interval: 500): earning curve (a) and testing result (b)\relax }}{2}{figure.caption.2}}
\newlabel{fig:param_0057}{{2}{2}{DQN with fixed Q-targets (updating interval: 500): earning curve (a) and testing result (b)\relax }{figure.caption.2}{}}
\citation{LillicrapContinuouscontroldeep2015}
\newlabel{fig:train_param_0051}{{3a}{3}{\relax }{figure.caption.3}{}}
\newlabel{sub@fig:train_param_0051}{{a}{3}{\relax }{figure.caption.3}{}}
\newlabel{fig:train_param_0045}{{3b}{3}{\relax }{figure.caption.3}{}}
\newlabel{sub@fig:train_param_0045}{{b}{3}{\relax }{figure.caption.3}{}}
\newlabel{fig:train_param_0082}{{3c}{3}{\relax }{figure.caption.3}{}}
\newlabel{sub@fig:train_param_0082}{{c}{3}{\relax }{figure.caption.3}{}}
\newlabel{fig:train_param_0083}{{3d}{3}{\relax }{figure.caption.3}{}}
\newlabel{sub@fig:train_param_0083}{{d}{3}{\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces DQN with fixed Q-targets (updating interval: 500): $\alpha =2.5\times 10^{-4}$ (a), $\alpha =2\times 10^{-4}$ (b), $\alpha =5\times 10^{-2}$ (c), and $\alpha =5\times 10^{-6}$ (d).\relax }}{3}{figure.caption.3}}
\newlabel{fig:param_0000}{{3}{3}{DQN with fixed Q-targets (updating interval: 500): $\alpha =2.5\times 10^{-4}$ (a), $\alpha =2\times 10^{-4}$ (b), $\alpha =5\times 10^{-2}$ (c), and $\alpha =5\times 10^{-6}$ (d).\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Experiment 2}{3}{subsection.2.2}}
\newlabel{experiment2}{{2.2}{3}{Experiment 2}{subsection.2.2}{}}
\newlabel{fig:train_param_0058}{{4a}{3}{\relax }{figure.caption.4}{}}
\newlabel{sub@fig:train_param_0058}{{a}{3}{\relax }{figure.caption.4}{}}
\newlabel{fig:test_param_0058}{{4b}{3}{\relax }{figure.caption.4}{}}
\newlabel{sub@fig:test_param_0058}{{b}{3}{\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces DQN with "soft update" ($\tau =0.02$): learning curve (a) and testing result (b)\relax }}{3}{figure.caption.4}}
\newlabel{fig:param_0058}{{4}{3}{DQN with "soft update" ($\tau =0.02$): learning curve (a) and testing result (b)\relax }{figure.caption.4}{}}
\citation{vanHasseltDeepReinforcementLearning2015}
\newlabel{fig:train_param_0059}{{5a}{4}{\relax }{figure.caption.5}{}}
\newlabel{sub@fig:train_param_0059}{{a}{4}{\relax }{figure.caption.5}{}}
\newlabel{fig:test_param_0059}{{5b}{4}{\relax }{figure.caption.5}{}}
\newlabel{sub@fig:test_param_0059}{{b}{4}{\relax }{figure.caption.5}{}}
\newlabel{fig:train_param_0060}{{5c}{4}{\relax }{figure.caption.5}{}}
\newlabel{sub@fig:train_param_0060}{{c}{4}{\relax }{figure.caption.5}{}}
\newlabel{fig:test_param_0060}{{5d}{4}{\relax }{figure.caption.5}{}}
\newlabel{sub@fig:test_param_0060}{{d}{4}{\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces DQN with "soft update" ($\tau =0.01$): learning curve (a) and testing result (b); and ($\tau =0.05$): learning curve (c) and testing result (d)\relax }}{4}{figure.caption.5}}
\newlabel{fig:param_00590060}{{5}{4}{DQN with "soft update" ($\tau =0.01$): learning curve (a) and testing result (b); and ($\tau =0.05$): learning curve (c) and testing result (d)\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Experiment 3}{4}{subsection.2.3}}
\newlabel{experiment3}{{2.3}{4}{Experiment 3}{subsection.2.3}{}}
\newlabel{fig:train_param_0083}{{6a}{4}{\relax }{figure.caption.6}{}}
\newlabel{sub@fig:train_param_0083}{{a}{4}{\relax }{figure.caption.6}{}}
\newlabel{fig:train_param_0084}{{6b}{4}{\relax }{figure.caption.6}{}}
\newlabel{sub@fig:train_param_0084}{{b}{4}{\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces DDQN with fixed Q targets (update interval: 500) at $\alpha =5\times 10^{-4}$ (a), and $\alpha =5\times 10^{-2}$ (b).\relax }}{4}{figure.caption.6}}
\newlabel{fig:nnbestparam}{{6}{4}{DDQN with fixed Q targets (update interval: 500) at $\alpha =5\times 10^{-4}$ (a), and $\alpha =5\times 10^{-2}$ (b).\relax }{figure.caption.6}{}}
\bibstyle{unsrt}
\bibdata{ref}
\bibcite{MnihPlayingAtariDeep2013}{1}
\bibcite{RoderickImplementingDeepQNetwork2017}{2}
\bibcite{LillicrapContinuouscontroldeep2015}{3}
\bibcite{vanHasseltDeepReinforcementLearning2015}{4}
\newlabel{fig:train_param_0077}{{7a}{5}{\relax }{figure.caption.7}{}}
\newlabel{sub@fig:train_param_0077}{{a}{5}{\relax }{figure.caption.7}{}}
\newlabel{fig:train_param_0079}{{7b}{5}{\relax }{figure.caption.7}{}}
\newlabel{sub@fig:train_param_0079}{{b}{5}{\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces DDQN with soft update ($\alpha =5\times 10^{-4}$) at $\tau =0.05$ (c), and $\tau =0.02$ (d).\relax }}{5}{figure.caption.7}}
\newlabel{fig:nnbestparam}{{7}{5}{DDQN with soft update ($\alpha =5\times 10^{-4}$) at $\tau =0.05$ (c), and $\tau =0.02$ (d).\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Difficulties}{5}{section.3}}
\newlabel{difficulties}{{3}{5}{Difficulties}{section.3}{}}
